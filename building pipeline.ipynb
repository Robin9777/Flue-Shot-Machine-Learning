{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43806e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import utilsfunc as uf\n",
    "from config import SELECTED_FEATURES, TARGETS\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1c038e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26707\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"training_set_features.csv\", index_col=\"respondent_id\")\n",
    "mappings = uf.read_json(\"mapping.json\")\n",
    "results = pd.read_csv(\"training_set_labels.csv\", index_col=\"respondent_id\")\n",
    "\n",
    "df = df[SELECTED_FEATURES]\n",
    "df = pd.concat([df, results], axis=1)\n",
    "\n",
    "for col, mapping in mappings.items():\n",
    "    df[col] = df[col].map(mapping)\n",
    "\n",
    "X = df.drop(columns=TARGETS)\n",
    "y = df[TARGETS[0]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a503442",
   "metadata": {},
   "outputs": [],
   "source": [
    "Column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\"), SELECTED_FEATURES)\n",
    "    ], \n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9acef9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'dt__criterion': ['gini', 'entropy'],\n",
    "    'dt__max_depth': [3, 4, 5, 6, 7, 10],\n",
    "    'dt__min_samples_split': [2, 3, 4, 5, 7, 10],\n",
    "    'dt__min_samples_leaf': [1, 2, 3, 4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d502e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = Pipeline([\n",
    "    ('drop_missing', uf.DropMissingTransformer(threshold=0.2)),\n",
    "    ('column_transformer', Column_transformer),\n",
    "    ('selectkbest', SelectKBest(score_func=chi2, k=10)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdce65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline_model,\n",
    "    param_grid=params,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a787d53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8161766518310996\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22c5eab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90      4212\n",
      "           1       0.69      0.41      0.51      1130\n",
      "\n",
      "    accuracy                           0.84      5342\n",
      "   macro avg       0.77      0.68      0.71      5342\n",
      "weighted avg       0.82      0.84      0.82      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8198540411298523"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nClassification Report for Test set\")\n",
    "print(classification_report(y_test, grid_search.predict(X_test)))\n",
    "roc_auc_score(y_test, grid_search.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "545faff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training_set_features.csv\", index_col=\"respondent_id\")\n",
    "mappings = uf.read_json(\"mapping.json\")\n",
    "results = pd.read_csv(\"training_set_labels.csv\", index_col=\"respondent_id\")\n",
    "\n",
    "results = results[TARGETS[0]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, results, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb86e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DecisionTreePipeline import *\n",
    "\n",
    "dt_pipeline = DTPipeline()\n",
    "pipeline_model = dt_pipeline.build_pipeline(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b09df912",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'selectkbest__k': [5, 10, 15, 'all'],\n",
    "    'dt__criterion': ['gini', 'entropy'],\n",
    "    'dt__max_depth': [4, 5, 6],\n",
    "    'dt__min_samples_split': [2, 3, 4, 5],\n",
    "    'dt__min_samples_leaf': [3, 4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63c2d503",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 1440 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1440 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 833, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1336, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 613, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 547, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\joblib\\memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1484, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 910, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1336, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\", line 563, in fit\n    X, y = validate_data(\n           ~~~~~~~~~~~~~^\n        self, X, y, accept_sparse=[\"csr\", \"csc\"], multi_output=True\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2919, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1314, in check_X_y\n    X = check_array(\n        X,\n    ...<12 lines>...\n        input_name=\"X\",\n    )\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_array\n    _assert_all_finite(\n    ~~~~~~~~~~~~~~~~~~^\n        array,\n        ^^^^^^\n    ...<2 lines>...\n        allow_nan=ensure_all_finite == \"allow-nan\",\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 133, in _assert_all_finite\n    _assert_all_finite_element_wise(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        X,\n        ^^\n    ...<4 lines>...\n        input_name=input_name,\n        ^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 182, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nSelectKBest does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m grid_search = GridSearchCV(\n\u001b[32m      2\u001b[39m     estimator=pipeline_model,\n\u001b[32m      3\u001b[39m     param_grid=params,\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m,\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1053\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1047\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1048\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1049\u001b[39m     )\n\u001b[32m   1051\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1056\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1057\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1612\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1610\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1611\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1612\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1030\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) != n_candidates * n_splits:\n\u001b[32m   1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1025\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcv.split and cv.get_n_splits returned \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1026\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1027\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(n_splits, \u001b[38;5;28mlen\u001b[39m(out) // n_candidates)\n\u001b[32m   1028\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1030\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[32m   1033\u001b[39m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[32m   1034\u001b[39m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[32m   1035\u001b[39m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:479\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    473\u001b[39m     all_fits_failed_message = (\n\u001b[32m    474\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    475\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    478\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    482\u001b[39m     some_fits_failed_message = (\n\u001b[32m    483\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    484\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    489\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 1440 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1440 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 833, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1336, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 613, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 547, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\joblib\\memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1484, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 910, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1336, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\", line 563, in fit\n    X, y = validate_data(\n           ~~~~~~~~~~~~~^\n        self, X, y, accept_sparse=[\"csr\", \"csc\"], multi_output=True\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2919, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1314, in check_X_y\n    X = check_array(\n        X,\n    ...<12 lines>...\n        input_name=\"X\",\n    )\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_array\n    _assert_all_finite(\n    ~~~~~~~~~~~~~~~~~~^\n        array,\n        ^^^^^^\n    ...<2 lines>...\n        allow_nan=ensure_all_finite == \"allow-nan\",\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 133, in _assert_all_finite\n    _assert_all_finite_element_wise(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        X,\n        ^^\n    ...<4 lines>...\n        input_name=input_name,\n        ^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\SandBox\\Flue Shot\\Flue-Shot-Machine-Learning\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 182, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nSelectKBest does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline_model,\n",
    "    param_grid=params,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9921ab42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(8549)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(pipeline_model[:-2].fit_transform(X_train, y_train)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa039e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8162074508686962\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
